{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7af790b9-f4cc-40e0-a28a-7f11fc403b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d9d6b6b-7a15-4158-8977-ed5c1ec5a3da",
   "metadata": {},
   "source": [
    "### Pretrain datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9604e3d9-1c92-4c3b-b799-698a1e7cb026",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████████| 4/4 [00:20<00:00,  5.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 38.6 s, sys: 42.7 s, total: 1min 21s\n",
      "Wall time: 56.1 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "import tqdm, torch\n",
    "\n",
    "df_trans = pq.read_table('data/trans_filtered.pq').to_pandas()\n",
    "\n",
    "cols = ['url_host', 'request_cnt', 'part_of_day', 'event_time']\n",
    "\n",
    "for col in tqdm.tqdm(cols):\n",
    "    df_trans[col] = df_trans[col].apply(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbd7a8da-f0c8-4af6-be82-b891249003ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "df_train_trans, df_valid_trans = train_test_split(df_trans, test_size = 0.1, random_state = 42)\n",
    "df_train_trans = df_train_trans.to_dict(orient='records')\n",
    "df_valid_trans = df_valid_trans.to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39b04931-64ba-4817-9cba-a124c5382ff7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(373785, 41532)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df_train_trans), len(df_valid_trans)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f223e8d-dfde-4c4b-9c71-6cf3c744c0a9",
   "metadata": {},
   "source": [
    "## Train MLM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82cc0f45-6d4c-4026-ab33-bb58d1c5a5c7",
   "metadata": {},
   "source": [
    "### Model definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a491a9e2-62f6-41f8-9010-0cec157dbded",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from functools import partial\n",
    "from ptls.nn import TrxEncoder, TransformerEncoder\n",
    "from ptls.nn import PBLinear, PBL2Norm, PBLayerNorm\n",
    "from ptls.frames.bert import MLMPretrainModule\n",
    "\n",
    "trx_encoder_params = dict(\n",
    "    embeddings_noise=0.003,\n",
    "    numeric_values={'request_cnt': 'identity'},\n",
    "    embeddings={ \n",
    "        'part_of_day': {'in': 4, 'out': 1},\n",
    "        'url_host': {'in': 132025, 'out': 512}\n",
    "    }\n",
    ")\n",
    "\n",
    "trx_encoder = TrxEncoder(**trx_encoder_params)\n",
    "trx_encoder = torch.nn.Sequential(trx_encoder, PBLinear(trx_encoder.output_size, 256), PBL2Norm())\n",
    "\n",
    "seq_encoder = TransformerEncoder(input_size=256, is_reduce_sequence=True)\n",
    "\n",
    "model = MLMPretrainModule(trx_encoder=trx_encoder, seq_encoder=seq_encoder, hidden_size=256, total_steps=100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c351fd-524a-4c32-a394-a679734d92dc",
   "metadata": {},
   "source": [
    "### Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3f1ea07f-9532-4c85-b961-377ad1ee16fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ptls.data_load.datasets import MemoryMapDataset\n",
    "from ptls.data_load.iterable_processing.feature_filter import FeatureFilter\n",
    "from ptls.frames.coles.split_strategy import SampleSlices\n",
    "from ptls.frames import PtlsDataModule\n",
    "from ptls.frames.bert import MlmDataset\n",
    "\n",
    "\n",
    "train_ds = MemoryMapDataset(data=df_train_trans)\n",
    "valid_ds = MemoryMapDataset(data=df_valid_trans)\n",
    "\n",
    "train_data=MlmDataset(train_ds, min_len=25, max_len=256)\n",
    "valid_data=MlmDataset(valid_ds, min_len=25, max_len=256)\n",
    "\n",
    "dl = PtlsDataModule(train_data=train_data, valid_data=valid_data, train_num_workers=16, train_batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faaf7ed2-9782-4439-8a86-32808d4fff8d",
   "metadata": {},
   "source": [
    "### Trainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0c2b3322-7818-44a6-adf8-a9322a315b68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True, used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "import logging\n",
    "\n",
    "trainer = pl.Trainer(\n",
    "    max_steps=50000,\n",
    "    limit_val_batches=100,\n",
    "    gpus=[0],\n",
    "    enable_progress_bar=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70e8672a-97cd-4cb9-9ad4-ad3d1e88d69f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0,1]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "logger.version = 19\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name            | Type               | Params\n",
      "-------------------------------------------------------\n",
      "0 | trx_encoder     | Sequential         | 67.7 M\n",
      "1 | seq_encoder     | TransformerEncoder | 2.4 M \n",
      "2 | fn_norm_predict | PBShell            | 0     \n",
      "3 | loss_fn         | QuerySoftmaxLoss   | 0     \n",
      "4 | train_mlm_loss  | MeanMetric         | 0     \n",
      "5 | valid_mlm_loss  | MeanMetric         | 0     \n",
      "-------------------------------------------------------\n",
      "70.1 M    Trainable params\n",
      "0         Non-trainable params\n",
      "70.1 M    Total params\n",
      "280.417   Total estimated model params size (MB)\n"
     ]
    }
   ],
   "source": [
    "print(f'logger.version = {trainer.logger.version}')\n",
    "trainer.fit(model, dl)\n",
    "print(trainer.logged_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64b7e9fd-84df-4f10-9a0e-8c08dc8ca610",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), \"mlm-emb.pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ea85365-d6fa-4c81-8ab3-5f4cf98b9438",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81c0849f-92b6-4a6e-9b22-656cf8344397",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_state_dict(torch.load(\"mlm-emb.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "357a9c4e-778f-4a1d-a5ce-4f7fe3b97045",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import tqdm, torch\n",
    "\n",
    "df_trans = pq.read_table('data/trans_filtered.pq').to_pandas()\n",
    "\n",
    "cols = ['url_host', 'request_cnt', 'part_of_day', 'event_time']\n",
    "\n",
    "for col in tqdm.tqdm(cols):\n",
    "    df_trans[col] = df_trans[col].apply(torch.tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "525553f1-6983-45c3-b6cd-9d9a50ab6c04",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "import tqdm\n",
    "from ptls.data_load.datasets import inference_data_loader\n",
    "import numpy as np\n",
    "\n",
    "def pooling_inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            x = model.trx_encoder(batch.to(device)).payload\n",
    "            out_max = torch.max(x, dim=1)[0]\n",
    "            out_min = torch.min(x, dim=1)[0]\n",
    "            out_mean = torch.mean(x, dim=1)\n",
    "            out_std = torch.std(x, dim=1)\n",
    "            features = torch.cat([out_max, out_min, out_mean, out_std], dim=1)      \n",
    "            X += [features]\n",
    "    return X\n",
    "\n",
    "def embed_inference(model, dl, device='cuda:0'):\n",
    "    \n",
    "    model.to(device)\n",
    "    X = []\n",
    "    for batch in tqdm.tqdm(dl):\n",
    "        with torch.no_grad():\n",
    "            z = model.trx_encoder(batch.to(device))\n",
    "            features = model.seq_encoder(z)\n",
    "            X += [features]\n",
    "    return X\n",
    "\n",
    "dl = inference_data_loader(df_trans.to_dict(orient='records'), num_workers=0, batch_size=128)\n",
    "#X_mlm = torch.vstack(embed_inference(model, dl, )).cpu().numpy()\n",
    "X_pool = torch.vstack(pooling_inference(model, dl, )).cpu().numpy()\n",
    "#X_embeds = np.concatenate([X_mlm, X_pool], axis=1)\n",
    "X_embeds = X_pool\n",
    "\n",
    "df_embeds = pd.DataFrame(X_embeds, columns=[f\"mlm_{e}\" for e in range(X_embeds.shape[1])])\n",
    "df_embeds['user_id'] = df_trans['user_id']\n",
    "df_embeds.to_csv('./data/mlm_512.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b34f2f38-af86-417a-904f-4c235e6fa30b",
   "metadata": {},
   "source": [
    "## Downstream"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "249e125e-b4f2-458a-8a83-5a897b667e5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "import bisect\n",
    "import numpy as np\n",
    "\n",
    "df_embeds = pd.read_csv('./data/mlm_512.csv')\n",
    "df_public = pq.read_table('data/public_train.pqt').to_pandas().sort_values(by='user_id')\n",
    "\n",
    "def age_bucket(x):\n",
    "    return bisect.bisect_left([18,25,35,45,55,65], x)\n",
    "\n",
    "y_age = df_public['age']\n",
    "y_age = np.array(list(map(age_bucket, y_age)))\n",
    "y_gender = np.array(df_public['is_male'])\n",
    "\n",
    "X = df_public\n",
    "X = X.merge(df_embeds, on=\"user_id\", how='inner')\n",
    "del X['user_id'], X['age'], X['is_male']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1256856-3585-4b1d-ab90-68d7f2e74847",
   "metadata": {},
   "source": [
    "## Gender"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91510b6-e068-4b06-a703-ece8a251280e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# %%time\n",
    "\n",
    "from catboost import CatBoostClassifier, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "not_na_gender = (y_gender != 'NA') & (y_gender != None)\n",
    "x_train, x_test_gender, y_train, y_test_gender = train_test_split(X[not_na_gender], y_gender[not_na_gender], test_size = 0.1, random_state = 42)\n",
    "\n",
    "clf_gender = CatBoostClassifier(\n",
    "    iterations=1000,\n",
    "    custom_metric=[metrics.AUC()],\n",
    "    use_best_model=True,\n",
    "    random_seed=42)\n",
    "clf_gender.fit(x_train, y_train, metric_period=100, eval_set=(x_test_gender, y_test_gender))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36e9073f-a2e5-4380-b3b6-7afbb95503e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GINI по полу 0.694\n"
     ]
    }
   ],
   "source": [
    "print(f'GINI по полу {2 * roc_auc_score(y_test_gender, clf_gender.predict_proba(x_test_gender)[:,1]) - 1:2.3f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f90007-39ca-413f-bb25-4fb6c4567417",
   "metadata": {},
   "source": [
    "# Age"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37c4697a-1ad9-4b11-904a-5d2cae5c0945",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "not_na_age = ~np.isnan(y_age)\n",
    "x_train, x_test_age, y_train, y_test_age = train_test_split(X[not_na_age], y_age[not_na_age], test_size = 0.1, random_state = 42)\n",
    "\n",
    "clf_age = CatBoostClassifier(iterations=1000,\n",
    "    custom_metric=[metrics.Accuracy()],\n",
    "    use_best_model=True,\n",
    "    random_seed=42)\n",
    "clf_age.fit(x_train, y_train, metric_period=100, eval_set=(x_test_age, y_test_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d63be1d4-15a0-4c0a-9c5a-5d836a7a24ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         <18       0.00      0.00      0.00       109\n",
      "       18-25       0.53      0.35      0.42      3238\n",
      "       25-34       0.50      0.64      0.56      8863\n",
      "       35-44       0.41      0.51      0.45      7773\n",
      "       45-54       0.38      0.23      0.29      4218\n",
      "       55-65       0.39      0.22      0.29      2254\n",
      "         65+       0.38      0.02      0.03       545\n",
      "\n",
      "    accuracy                           0.45     27000\n",
      "   macro avg       0.37      0.28      0.29     27000\n",
      "weighted avg       0.44      0.45      0.43     27000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test_age, clf_age.predict(x_test_age), \\\n",
    "                            target_names = ['<18', '18-25','25-34', '35-44', '45-54', '55-65', '65+']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "83148af4-776b-4bad-8195-cbc282d2a501",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.6720000000000002"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.752 + 2*0.46"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3665984e-8f8a-4ae0-b857-a6afc34a7c39",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "0.760 + 2*0.47"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ef9df4-d8ab-4899-b31c-4b165ef3e6f2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ptls",
   "language": "python",
   "name": "ptls"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
